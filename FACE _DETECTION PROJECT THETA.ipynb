{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffa6115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolutional neural network\n",
    "# it is a type of neural network in which feature selection is performed automatically\n",
    "#and selected one are fed to hidden layers continously\n",
    "\n",
    "# when we make object detection\n",
    "#folder like structure\n",
    " #train \n",
    "    #object1\n",
    "    #object2\n",
    "    #object3 \n",
    "    #object 4\n",
    "    #object 5\n",
    " #test \n",
    "      #object1\n",
    "    #object2\n",
    "    #object3 \n",
    "    #object 4\n",
    "    #object 5\n",
    "    \n",
    "# in image processing we do data augmentation \n",
    "#data agumentation - we create samples from previous samples by inducing noise in them\n",
    "#rescale- it is values that got multiplies by pixels to get their scale into one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc16a2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1314 images belonging to 1 classes.\n",
      "Found 194 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(zoom_range=0.2,\n",
    "                                shear_range=0.2,\n",
    "                                rescale=1/255)\n",
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "train_dataset=train_datagen.flow_from_directory(r\"C:\\Users\\Hpane\\OneDrive\\Desktop\\face detection\\train-20240912T115331Z-001\",\n",
    "                                               class_mode='binary',\n",
    "                                               target_size=(150,150),\n",
    "                                               batch_size=16)\n",
    "\n",
    "test_dataset=test_datagen.flow_from_directory(r\"C:\\Users\\Hpane\\OneDrive\\Desktop\\face detection\\test-20240912T134642Z-001\",\n",
    "                                               class_mode='binary',\n",
    "                                               target_size=(150,150),\n",
    "                                               batch_size=16)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc0455c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hpane\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hpane\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 249ms/step - accuracy: 0.9550 - loss: 0.0430 - val_accuracy: 1.0000 - val_loss: 2.7143e-14\n",
      "Epoch 2/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 122ms/step - accuracy: 1.0000 - loss: 4.1648e-14 - val_accuracy: 1.0000 - val_loss: 2.6964e-14\n",
      "Epoch 3/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 132ms/step - accuracy: 1.0000 - loss: 1.2026e-13 - val_accuracy: 1.0000 - val_loss: 2.6963e-14\n",
      "Epoch 4/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 183ms/step - accuracy: 1.0000 - loss: 1.0133e-12 - val_accuracy: 1.0000 - val_loss: 2.6962e-14\n",
      "Epoch 5/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 171ms/step - accuracy: 1.0000 - loss: 3.5686e-14 - val_accuracy: 1.0000 - val_loss: 2.6962e-14\n",
      "Epoch 6/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 129ms/step - accuracy: 1.0000 - loss: 1.0567e-13 - val_accuracy: 1.0000 - val_loss: 2.6962e-14\n",
      "Epoch 7/50\n",
      "\u001b[1m20/83\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 4.5579e-16"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow .keras.layers import Conv2D,MaxPool2D,Dense,Flatten\n",
    "cnn=Sequential()\n",
    "# in convolution one filter is convolve over the surface of image and generate a feature map\n",
    "#main goal extract out all features of image one by one \n",
    "cnn.add(Conv2D(input_shape=(150,150,3),filters=32,kernel_size=3))\n",
    "#pooling:it is used to reducing the size of feature app\n",
    "#types of pooling \n",
    "#maxpool:filter will pick max value from its shape\n",
    "#average pool:filter will pick average of values in its shape\n",
    "cnn.add(MaxPool2D(pool_size=2,strides=2))\n",
    "\n",
    "cnn.add(Conv2D(filters=16,kernel_size=3))\n",
    "cnn.add(MaxPool2D(pool_size=2,strides=2))\n",
    "cnn.add(Flatten())   #used to convert 2d array to 1 d\n",
    "cnn.add(Dense(units=120,activation=\"relu\"))\n",
    "cnn.add(Dense(units=1,activation=\"sigmoid\"))\n",
    "cnn.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "cnn.fit(train_dataset,validation_data=test_dataset,epochs=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "218d6dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred=cnn.predict(test_dataset)\n",
    "y_pred=np.where(y_pred>0.5,1,0)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a0768",
   "metadata": {},
   "outputs": [],
   "source": [
    " cnn.save(r\"C:\\Users\\Hpane\\OneDrive\\Desktop\\face detectioncnn.keras\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1cfa4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12887733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8cb1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fd7463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2478bc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca3fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8721c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
